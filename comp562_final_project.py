# -*- coding: utf-8 -*-
"""COMP562 Final Project().ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fpOzzX14KoWKkjZp8bm04hgKbMO8YR4S
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import log_loss, roc_auc_score
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (StandardScaler, MinMaxScaler, RobustScaler,
                                  OneHotEncoder, LabelEncoder, OrdinalEncoder)
from sklearn.linear_model import LogisticRegression

from xgboost import XGBClassifier

!pip install tensorflow
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
import xgboost as xgb
from sklearn.metrics import accuracy_score

"""# Import train and test datasets"""

train_path = '/content/drive/My Drive/562/train.csv'
test_path = '/content/drive/My Drive/562/test.csv'
df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

df_train.dtypes

df_train.describe().T

# prompt: identify all categorical column and numerical column.

categorical_cols = [col for col in df_train.columns if df_train[col].dtypes == 'object']
numerical_cols = [col for col in df_train.columns if df_train[col].dtypes != 'object']
label_col = 'status'

# prompt: Using dataframe df_train: for categorical column, use countplot to plot the data distribution for each status; for numerical column, use kdeplot to plot the data distribution for each status

import matplotlib.pyplot as plt
import seaborn as sns

for col in df_train.select_dtypes(['object']).columns:
    sns.countplot(x=col, hue='Status', data=df_train)
    plt.show()

for col in df_train.select_dtypes(['float64']).columns:
    sns.kdeplot(x=col, hue='Status', data=df_train)
    plt.show()

for col in df_train.select_dtypes(['int64']).columns:
    if col is 'id':
      continue
    else:
      sns.kdeplot(x=col, hue='Status', data=df_train)
      plt.show()

"""# Data Processing"""

# Age normalization
normalize_age = lambda x: x // 365
for df in [df_train, df_test]:
    df['Age'] = df['Age'].apply(normalize_age)

seed = 42
test_size = 0.2
val_size = 0.1
target = 'Status'

for data in [df_train, df_test]:
    data['Drug'].replace(['Placebo', 'D-penicillamine'], [0, 1], inplace=True)
    data['Sex'].replace(['M', 'F'], [0, 1], inplace=True)
    data['Ascites'].replace(['N', 'Y'], [0, 1], inplace=True)
    data['Hepatomegaly'].replace(['N', 'Y'], [0, 1], inplace=True)
    data['Spiders'].replace(['N', 'Y'], [0, 1], inplace=True)
    data['Edema'].replace(['N', 'Y', 'S'], [0, 1, 2], inplace=True)

df_train['Bilirubin'] = np.log(np.sqrt(df_train['Bilirubin']))
df_test['Bilirubin'] = np.log(np.sqrt(df_test['Bilirubin']))

df_train = df_train.query('Cholesterol < 750')

df_train['Cholesterol'] = np.log1p(df_train['Cholesterol'])
df_test['Cholesterol'] = np.log1p(df_test['Cholesterol'])

df_train['Copper'] = np.log1p(df_train['Copper'].astype(int))
df_test['Copper'] = np.log1p(df_test['Copper'].astype(int))

df_train = df_train.query('Alk_Phos < 2000')
df_train = df_train.query('SGOT < 250')
df_train = df_train.query('Tryglicerides < 250')
df_train = df_train.query('Prothrombin < 13')

df_train['Prothrombin'] = np.log1p(df_train['Prothrombin'])
df_test['Prothrombin'] = np.log1p(df_test['Prothrombin'])

for col in df_train.select_dtypes(['object']).columns:
    if col != 'Status':
      sns.countplot(x=col, hue='Status', data=df_train)
      plt.show()

for col in df_train.select_dtypes(['float64']).columns:
    sns.kdeplot(x=col, hue='Status', data=df_train)
    plt.show()

for col in df_train.select_dtypes(['int64']).columns:
    if col != 'id':
      sns.kdeplot(x=col, hue='Status', data=df_train)
      plt.show()

df_train[target].replace(['D', 'C', 'CL'], [0, 1, 2], inplace=True)

X = df_train.drop(target, axis=1)
X = X.drop('id', axis=1)
y = df_train[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=seed)
X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=val_size, shuffle=True, random_state=seed)

scaler = MinMaxScaler().set_output(transform='pandas')
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

y_train_label = y_train
y_val_label = y_val
y_test_label = y_test

y_train = to_categorical(y_train)
y_val = to_categorical(y_val)
y_test = to_categorical(y_test)

"""# Models

**Basic Neural Network**
"""

X_train.shape

model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),
    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),
    Dense(3, activation='softmax')
    ])

model.compile( optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005),
              loss=tf.keras.losses.CategoricalCrossentropy(),
               metrics=['accuracy'])

early_stopping = EarlyStopping(
    monitor="val_loss",
    min_delta=0.0001,
    patience=10,
    verbose=1,
    mode="auto",
    restore_best_weights=True,)

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Plot loss curve

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

# Predict on test dataset
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
actual_classes = np.argmax(y_test, axis=1)

# Evaluate accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(actual_classes, predicted_classes)
print(f"Model accuracy score with feed forward neural network: {accuracy}")

# Compute the confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(actual_classes, predicted_classes)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

"""**Random Forest**"""

rfc = RandomForestClassifier(n_estimators=10, random_state=seed)
rfc.fit(X_train, y_train)

rfc_500 = RandomForestClassifier(n_estimators=500, random_state=seed)
rfc_500.fit(X_train, y_train)

y_pred = rfc.predict(X_test)
predicted = np.argmax(y_pred, axis=1)

y_pred_500 = rfc_500.predict(X_test)
predicted_500 = np.argmax(y_pred_500, axis=1)

# Evaluate accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy score with 10 decision-trees: {accuracy}")

accuracy_500 = accuracy_score(y_test, y_pred_500)
print(f"Model accuracy score with 500 decision-trees: {accuracy}")

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

# Confusion Matrix
from sklearn.metrics import multilabel_confusion_matrix
c_matrix =  confusion_matrix(actual_classes, predicted)
plt.figure(figsize=(10, 8))
sns.heatmap(c_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

from sklearn.metrics import multilabel_confusion_matrix
c_matrix =  confusion_matrix(actual_classes, predicted_500)
plt.figure(figsize=(10, 8))
sns.heatmap(c_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""**Features**"""

features = pd.Series(rfc_500.feature_importances_, index=X_train.columns).sort_values(ascending=False)
print(features)
sns.barplot(x=features, y=features.index)
plt.title("Important Features Chart")
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.show()

features = pd.Series(rfc.feature_importances_, index=X_train.columns).sort_values(ascending=False)
print(features)
sns.barplot(x=features, y=features.index)
plt.title("Important Features Chart")
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.show()

"""**XGBoost**"""

unique_classes_train = np.unique(y_train)
print(f"There are {len(y_train)} values in the training set for y. Each of these values is length {len(y_train[0])} and consists of {len(unique_classes_train)} unique classes.")

model = xgb.XGBClassifier(max_depth=4, learning_rate=0.3, objective='binary:logistic')
model.fit(X_train, y_train)
pred_y = model.predict(X_test)
predicted = np.argmax(pred_y, axis=1)

accuracy_score(actual_classes, predicted)

"""**Confusion Matrix for XGBoost**"""

c_matrix =  confusion_matrix(actual_classes, predicted)
plt.figure(figsize=(10, 8))
sns.heatmap(c_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

"""**Logistic Regression**"""

logreg = LogisticRegression()
logreg.fit(X_train, y_train_label)

y_pred = logreg.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test_label, y_pred)
print(f"Model accuracy score for logistic regression: {accuracy}")

"""**Confusion Matrix for Logistic Regression**"""

from sklearn.metrics import confusion_matrix
con_matrix = confusion_matrix(y_test_label, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(con_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

